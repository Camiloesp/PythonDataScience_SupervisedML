# Data Science in Python — Classification & Regression

This repository documents my learning, exercises, and insights from completing two Udemy courses focused on **Data Science in Python**:

- [Data Science in Python: Classification](https://www.udemy.com/course/data-science-in-python-classification)
- [Data Science in Python: Regression](https://www.udemy.com/course/data-science-in-python-regression)

Both courses emphasized practical, hands-on machine learning using Python, NumPy, pandas, scikit-learn, and matplotlib.

---

## 🧠 What I Learned

### Core Concepts
- The fundamentals of **machine learning** and **supervised learning**.
- The difference between **classification** and **regression** problems.
- How to prepare, clean, and normalize datasets for model training.
- How to evaluate model performance with metrics like accuracy, precision, recall, F1-score, and R².

### Regression Course
- Implemented models to predict continuous variables using:
  - **Linear Regression**
  - **Polynomial Regression**
  - **Ridge and Lasso Regression**
  - **Decision Tree and Random Forest Regression**
- Learned how to avoid **overfitting** using regularization and cross-validation.
- Visualized model fit and error distributions with matplotlib.

### Classification Course
- Built and trained models to categorize data using:
  - **Logistic Regression**
  - **K-Nearest Neighbors (KNN)**
  - **Decision Trees**
  - **Random Forests**
  - **Support Vector Machines (SVM)**
  - **Naive Bayes**
- Explored confusion matrices, ROC curves, and AUC as evaluation tools.
- Practiced handling **imbalanced datasets** and improving model performance with resampling and feature scaling.

---

## 🧰 Tools and Libraries Used

- **Python 3**
- **NumPy** – Numerical computing  
- **pandas** – Data manipulation and analysis  
- **matplotlib / seaborn** – Visualization  
- **scikit-learn** – Machine learning models and preprocessing  
- **Jupyter Notebook** – Interactive coding and data exploration  

---

## 📂 What’s Inside

This repository includes:
- Jupyter notebooks for both **classification** and **regression** projects.
- Datasets used in the courses (where permitted).
- Notes on key algorithms and formulas.
- Visualizations and model comparison charts.

---

## 🔍 Key Takeaways

- Data preprocessing is just as important as model selection.
- No single algorithm is “best” — performance depends on the data and problem type.
- Regularization and validation are crucial to prevent overfitting.
- Visualization helps to interpret both data and model behavior.
- Machine learning is iterative — **test, evaluate, refine, repeat**.

---

## 📈 Next Steps

After completing both courses, I plan to:
- Apply these techniques to real-world datasets (e.g., Kaggle competitions).
- Explore **unsupervised learning** (clustering and dimensionality reduction).
- Learn more advanced models such as **XGBoost**, **LightGBM**, and **neural networks**.

---

## 🧑‍💻 Author

**Camilo Espinosa**  
Data Science Enthusiast | Python Developer  
📍 Dallas, TX  

---

*These courses were an excellent introduction to machine learning with Python, providing both the theory and practical workflow needed to build predictive models.*
